{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:36.380624Z",
     "start_time": "2025-11-06T12:07:33.967010Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from timm import create_model\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b0f463f577d90dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:36.402918Z",
     "start_time": "2025-11-06T12:07:36.391207Z"
    }
   },
   "source": [
    "df = pd.read_csv(\"dataset/label.csv\", sep=',')\n",
    "rename_feelings = {\"Happy\": \"positive\",\"Sad\": \"negative\",\"Surprised\":\"positive\",\"Neutral\":\"positive\",\"Contempt\": \"negative\",\"Disgust\":\"negative\",\"Fear\": \"negative\", \"Anger\": \"negative\"}\n",
    "df['emotion'] = df['emotion'].replace(rename_feelings)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "label_encoder = LabelEncoder()\n",
    "df['emotion_encoded'] = label_encoder.fit_transform(df['emotion'])\n",
    "display(df.head(10))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     image   emotion  emotion_encoded\n",
       "0   48.jpg  negative                0\n",
       "1  114.jpg  negative                0\n",
       "2  105.jpg  negative                0\n",
       "3   90.jpg  negative                0\n",
       "4   66.jpg  negative                0\n",
       "5  150.jpg  negative                0\n",
       "6  136.jpg  negative                0\n",
       "7    6.jpg  negative                0\n",
       "8   77.jpg  positive                1\n",
       "9   41.jpg  negative                0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77.jpg</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.jpg</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "507e31bfdcf189b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:36.451229Z",
     "start_time": "2025-11-06T12:07:36.447684Z"
    }
   },
   "source": [
    "class extractImageFeatureResNetDataSet():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.scaler = transforms.Resize([224, 224])\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_name = self.data.iloc[idx]['image']\n",
    "        img_loc = 'dataset/images/'+str(image_name)\n",
    "        img = Image.open(img_loc)\n",
    "        t_img = self.normalize(self.to_tensor(self.scaler(img)))\n",
    "        return t_img, self.data.iloc[idx]['emotion_encoded'].item()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f8dfb49991309939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:36.614157Z",
     "start_time": "2025-11-06T12:07:36.611345Z"
    }
   },
   "source": "train_ImageDataset_ResNet = extractImageFeatureResNetDataSet(df)",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:38.264278Z",
     "start_time": "2025-11-06T12:07:36.658212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda'\n",
    "model = create_model('vit_base_patch16_224', pretrained=True, num_classes=2)  # Using a pretrained ViT model\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ],
   "id": "f52fd5f5e5f0ab67",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8d984fa9a099fb1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:07:38.282079Z",
     "start_time": "2025-11-06T12:07:38.277762Z"
    }
   },
   "source": [
    "def train_model(epochs=20):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    highest_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        predict_arr, gt_arr = [], []\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_ImageDataset_ResNet)):\n",
    "            train_subset = Subset(train_ImageDataset_ResNet, train_idx)\n",
    "            val_subset = Subset(train_ImageDataset_ResNet, val_idx)\n",
    "            train_loader = DataLoader(train_subset, batch_size=4, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_subset, batch_size=4, shuffle=False, num_workers=0)\n",
    "            for images, labels in train_loader:        \n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:        \n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    predict_arr = predict_arr + predicted.cpu().tolist()\n",
    "                    gt_arr = gt_arr + labels.cpu().tolist()                    \n",
    "        accuracy = accuracy_score(predict_arr, gt_arr)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}, Accuracy: {accuracy*100:.2f}%')\n",
    "            \n",
    "        if highest_accuracy < accuracy:\n",
    "            print(\"Saving this model\")\n",
    "            torch.save(model.state_dict(), 'best.pt')\n",
    "            highest_accuracy = accuracy\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T12:11:52.052252Z",
     "start_time": "2025-11-06T12:07:38.317280Z"
    }
   },
   "cell_type": "code",
   "source": "train_model()",
   "id": "62268b1ffd24dc4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2221704707030328, Accuracy: 44.08%\n",
      "Saving this model\n",
      "Epoch [2/20], Loss: 0.9061198027864579, Accuracy: 59.21%\n",
      "Saving this model\n",
      "Epoch [3/20], Loss: 0.9174340266373849, Accuracy: 55.92%\n",
      "Epoch [4/20], Loss: 0.8821507278949984, Accuracy: 59.21%\n",
      "Epoch [5/20], Loss: 0.8770522359878786, Accuracy: 62.50%\n",
      "Saving this model\n",
      "Epoch [6/20], Loss: 0.8927337661866219, Accuracy: 63.16%\n",
      "Saving this model\n",
      "Epoch [7/20], Loss: 0.8189782442585114, Accuracy: 66.45%\n",
      "Saving this model\n",
      "Epoch [8/20], Loss: 0.8060295975977375, Accuracy: 62.50%\n",
      "Epoch [9/20], Loss: 0.7656565868566113, Accuracy: 67.76%\n",
      "Saving this model\n",
      "Epoch [10/20], Loss: 1.185576147189544, Accuracy: 70.39%\n",
      "Saving this model\n",
      "Epoch [11/20], Loss: 0.5603437128687098, Accuracy: 81.58%\n",
      "Saving this model\n",
      "Epoch [12/20], Loss: 0.4542191581680409, Accuracy: 83.55%\n",
      "Saving this model\n",
      "Epoch [13/20], Loss: 0.352031247938172, Accuracy: 88.82%\n",
      "Saving this model\n",
      "Epoch [14/20], Loss: 0.8501323681444891, Accuracy: 67.11%\n",
      "Epoch [15/20], Loss: 0.37564632362656053, Accuracy: 87.50%\n",
      "Epoch [16/20], Loss: 0.2841349943435841, Accuracy: 90.79%\n",
      "Saving this model\n",
      "Epoch [17/20], Loss: 0.43375309265121037, Accuracy: 84.21%\n",
      "Epoch [18/20], Loss: 0.3293565214619101, Accuracy: 90.79%\n",
      "Epoch [19/20], Loss: 0.2549693800899237, Accuracy: 89.47%\n",
      "Epoch [20/20], Loss: 0.38317190759558034, Accuracy: 91.45%\n",
      "Saving this model\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiT",
   "language": "python",
   "name": "dit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
